%----------------------------------------------------------------------------------------
%	PACKAGES AND DOCUMENT CONFIGURATIONS
%----------------------------------------------------------------------------------------
\documentclass{scrartcl}

%\usepackage{mathptmx}
\usepackage{graphicx} % Required for the inclusion of images
\usepackage{easybmat}
\usepackage{natbib} % Required to change bibliography style to APA
\usepackage{amsmath} % Required for some math elements 
\usepackage{amssymb}
\usepackage{float}
\usepackage{caption}
\usepackage{subcaption}


\usepackage{datetime}

\setlength\parindent{0pt} % Removes all indentation from paragraphs

\renewcommand{\labelenumi}{\alph{enumi}.} % Make numbering in the enumerate environment by letter rather than number (e.g. section 6)

%\usepackage{times} % Uncomment to use the Times New Roman font

%----------------------------------------------------------------------------------------
%	DOCUMENT INFORMATION
%----------------------------------------------------------------------------------------

\title{CS 390E: Geometry Processing \\ Assignment 01} % Title
\subtitle{Linear Algebra}
\author{Anna Fr\"{u}hst\"{u}ck} % Author name

\newdate{date}{05}{02}{2017}
\date{\displaydate{date}}
\begin{document}

\maketitle % Insert the title, author and date

%----------------------------------------------------------------------------------------
%	SECTION 1
%----------------------------------------------------------------------------------------

\section{Matrix norm}
The matrix norm can be interpreted as the maximum amount of "stretching" that a matrix $A$ can do to a vector $x \rightarrow Ax$. 
The operator norm corresponding to the vector norm $\|\cdot\|$ is defined as 
$$ \|A\|_p = \sup_{x\neq0}\frac{\|Ax\|_p}{\|x\|_p} \text{ for } p\geq1$$

\subsection{Matrix norm inequalities}
\subsubsection*{Subadditivity}
\textit{Prove $\|A+B\|\leq\|A\|+\|B\|$:}

$$\|A+B\| = \max\|(A+B)x\| = \max_{\|x=1\|}\|Ax + Bx\|$$
$$\max_{\|x=1\|}\|Ax + Bx\| \leq \max_{\|x=1\|}\|Ax\| + \|Bx\| \leq \max_{\|x=1\|}\|Ax\| + \max_{\|x=1\|}\|Bx\| = \|A\| + \|B\|$$

\subsubsection*{Subordinance}
\textit{Prove $\|Ax\|\leq\|A\|\|x\|$:}

Definition of the operator norm: $\|A\| = \sup\frac{\|Ax\|}{\|x\|}$\\
multiply right and left side by $\|x\|$\\
$\rightarrow$ for the $x$ corresponding to the largest norm: $\|x\|\|A\| = \|Ax\|$\\
$\rightarrow$ in general: $\|x\|\|A\| \leq \|Ax\|$

\subsubsection*{Submultiplicativity}
\textit{Prove $\|AB\|\leq\|A\|\|B\|$:}
$$\|AB\| = \max_{x\neq0}\frac{\|ABx\|}{\|x\|} = \max_{x\neq0,~Bx\neq0}\frac{\|A(Bx)\|}{\|Bx\|}\frac{\|Bx\|}{\|x\|} \leq \max_{y\neq0}\frac{\|Ay\|}{\|y\|}\max_{x\neq0}\frac{\|Bx\|}{\|x\|} = \|A\|\|B\|$$

\section{Orthogonality}
\textit{Given a set of orthogonal vectors $\{v_1, v_2, ..., v_n\} \in \mathbb{R}_m$ with $m\geq n$, i.e., $v_i^T v_j = 0$, for $i\neq j$, then they are linearly independent. Why?}\\


If $v_i^T$ and $v_j$ are orthogonal, $v_i^T v_j = 0$.

Two vectors $v_i$ and $v_j$ are linearly independent if and only if the following property is true:

$$\text{If } c_1 \text{ and } c_2 \text{ are scalars such that } c_1v_i + c_2v_j = 0 \text{ then } c_1 = c_2 = 0.$$

Suppose $c_1v_1 + c_2v_2 + ... + c_nv_n = 0$, then multiply equation with $v_i$:\\
$$c_1\underbrace{v_1 \cdot v_i}_{=0} + c_2\underbrace{v_2 \cdot v_i}_{=0} + ...  + c_iv_i \cdot v_i+ ... + c_n\underbrace{v_n \cdot v_i}_{=0} = 0 \cdot v_i$$

All terms on the left side go to zero except one:
$$c_i \|v_i\|^2 = 0$$

$\rightarrow c_i = 0$, therefore $c_1 = ... = c_n = 0$ \\
%
%$$0 = (c_1v_i + c_2v_j)v_i = c_1(v_i \cdot v_i)+ c_2(v_j \cdot v_i) = c_1(v_i \cdot v_i) + c_2 \cdot 0 = 0 \rightarrow c_1 = 0$$
%
%If $c_1 = 0 \rightarrow 0 \cdot v_i + c_2v_j = 0 $ \\
%Suppose $c_2 \neq 0:  c_2v_j = 0  \rightarrow v_j = 0$

\section{Jordan Normal Form}
The Jordan normal form is a special type of block matrix. The Jordan matrix has the eigenvalues on the main diagonal and $1$s on the superdiagonal for each Jordan block. 
The shape of the Jordan normal form follows this structure, each subblock of the matrix shown here is called a Jordan block:
$$\left[ \begin{BMAT}{ccccccccc}{ccccccccc} 
\lambda_1&1 & & & & & & & \\
& \lambda_1&1 & & & & & & \\
& & \lambda_1& & & & & & \\
& & & \lambda_2&1& & & & \\
& & & & \lambda_2& & & & \\
& & & & & \lambda_3& & & \\
& & & & & & \ddots & & \\
& & & & & & & \lambda_n&1\\
& & & & & & & & \lambda_n 
\addpath{(0,6,1)rrruuulllddd}
\addpath{(3,4,1)rruulldd}
\addpath{(5,3,1)ruld}
\addpath{(7,0,1)rruulldd}
\end{BMAT} \right]$$
While not all $n \times n$ matrices are diagonalizable (they are only if $A$ has $n$ linearly independent eigenvectors), in general an invertible matrix $P$ can be found such that $A = PJP^{-1}$, where $J$ is in Jordan form, and as such "almost diagonal".
\begin{itemize}
	\item The eigenvalues of $J$ (and therefore $A$) are on the diagonal.
	\item The geometric multiplicity of an eigenvalue $\lambda_i$ (the maximum number of linearly independent eigenvectors associated with this eigenvalue) is equal to the number of Jordan blocks corresponding to $\lambda_i$.
	\item The sum of the sizes of all Jordan blocks corresponding to an eigenvalue $\lambda_i$ equals to the algebraic multiplicity of $J$ (i.e. the repeated occurrence of $\lambda_i$ in the characteristic polynomial of $A$).
	%\item  
\end{itemize}
\section{2D Mesh viewer}
Start MATLAB implementation from \texttt{matrix\_transformations\textbackslash main.m} (for custom exploration) or \texttt{matrix\_transformations\textbackslash auto2D.m} (for animated demonstration).

Special matrices can be input using the functions in \texttt{matrix.m} by specifying the dimensionality, the matrix type and the matrix parameters e.g. \texttt{m = matrix(2, 'rotation', 0.8)} to generate a 2D rotation matrix. Note that homogeneous transformation matrices require a dimensionality of 3 for 2D transformations.

Any matrix transformation can be applied to the current data stored in the \texttt{points} variable by calling the function \texttt{points = transformPoints(view, points, m)} where \texttt{view} is the current figure that needs to be updated after the transformation, \texttt{points} is the matrix storing the data and \texttt{m} is the matrix transformation to be applied to each data point.

Apply the function \texttt{analyzeMatrix(m)} to any matrix to inspect its determinant, eigenvalues, eigenvectors, Jordan matrix and condition number.
\subsubsection*{Rotation}
$$\left[ \begin{smallmatrix} 
	\cos\alpha & -\sin\alpha\\
	\sin\alpha & \cos\alpha 
\end{smallmatrix} \right]$$
\begin{center}\texttt{m = matrix(2, 'rotation', a)}\end{center}
\begin{figure}[H]
	\centering
	\begin{subfigure}{.41\textwidth}
		\centering
		\includegraphics[width=\linewidth]{img/normal}
	\end{subfigure}%
	\begin{subfigure}{.41\textwidth}
		\centering
		\includegraphics[width=\linewidth]{img/rotation}
	\end{subfigure}
	\caption{Rotation by an angle of 1.2 radians around the center}
	\label{fig:rot}
\end{figure}
\subsubsection*{Shear}
\noindent
\begin{center}
	\begin{minipage}{.3\linewidth}
		\begin{center}\textit{Shear along x axis}
		\end{center}
	$$\left[ \begin{smallmatrix} 
	1 & f\\
	0 & 1
	\end{smallmatrix} \right]$$
\end{minipage}%
\begin{minipage}{.3\linewidth}
			\begin{center}\textit{Shear along y axis}
			\end{center}
	$$\left[ \begin{smallmatrix} 
	1 & 0\\
	f & 1
	\end{smallmatrix} \right]$$
\end{minipage}
\end{center}
\begin{center}
	\texttt{m = matrix(2, 'shear', axis, f)}
\end{center}
\begin{figure}[H]
	\centering
	\begin{subfigure}{.41\textwidth}
		\centering
		\includegraphics[width=\linewidth]{img/normal}
	\end{subfigure}%
	\begin{subfigure}{.41\textwidth}
		\centering
		\includegraphics[width=\linewidth]{img/shear}
	\end{subfigure}
	\caption{Shear by a factor of 1.2 along the x axis}
	\label{fig:rot}
\end{figure}

\subsubsection*{Mirror}
for reflection along axis defined by unit vector $[x,y]$
$$\left[ \begin{smallmatrix} 
x^2 - y^2 & 2xy\\
2xy & y^2 - x^2 
\end{smallmatrix} \right]$$
\begin{center}
	\texttt{m = matrix(2, 'reflection', [x y])}
\end{center}
\begin{figure}[H]
	\centering
	\begin{subfigure}{.41\textwidth}
		\centering
		\includegraphics[width=\linewidth]{img/normal}
	\end{subfigure}%
	\begin{subfigure}{.41\textwidth}
		\centering
		\includegraphics[width=\linewidth]{img/reflection}
	\end{subfigure}
	\caption{Reflect across y axis (vector $[0,1]$)}
	\label{fig:rot}
\end{figure}

\subsubsection*{Scaling}
$$\left[ \begin{smallmatrix} 
s_x & 0\\
0 & s_y 
\end{smallmatrix} \right]$$

\begin{center}
	\texttt{m = matrix(2, 'scale', s\_x, s\_y)}
\end{center}

\begin{figure}[H]
	\centering
	\begin{subfigure}{.41\textwidth}
		\centering
		\includegraphics[width=\linewidth]{img/normal}
	\end{subfigure}%
	\begin{subfigure}{.41\textwidth}
		\centering
		\includegraphics[width=\linewidth]{img/scale}
	\end{subfigure}
	\caption{Anisotropic scale by factors $s_x = 2$ and $s_y = 1.5$}
	\label{fig:rot}
\end{figure}
\subsubsection*{Translation}
requires $3 \times 3$ homogeneous coordinates.
$$\left[ \begin{smallmatrix} 
1 & 0 & d_x\\
0 & 1 & d_y\\
0 & 0 & 1 
\end{smallmatrix} \right]$$

\begin{center}
	\texttt{m = matrix(3, 'translation', d\_x, d\_y)}
\end{center}
\begin{figure}[H]
	\centering
	\begin{subfigure}{.41\textwidth}
		\centering
		\includegraphics[width=\linewidth]{img/normal}
	\end{subfigure}%
	\begin{subfigure}{.41\textwidth}
		\centering
		\includegraphics[width=\linewidth]{img/translation}
	\end{subfigure}
	\caption{Translation by offsets $d_x = 2$ and $d_y = 1.5$}
	\label{fig:rot}
\end{figure}
\section{3D Mesh viewer}
\begin{flushleft}	
	Start MATLAB implementation from \texttt{matrix\_transformations\textbackslash main.m} (for custom exploration) or \texttt{matrix\_transformations\textbackslash auto3D.m} (for animated demonstration).
	
	Special matrices can be input using the functions in \texttt{matrix.m} by specifying the dimensionality, the matrix type and the matrix parameters e.g. \texttt{m = matrix(3, 'rotation', 'x', 0.8)} to generate a 3D rotation matrix. Note that homogeneous transformation matrices require a dimensionality of 4 for 3D transformations.
	
	Any matrix transformation can be applied to the current data stored in the \texttt{points} variable by calling the function \texttt{points = transformPoints(view, points, m)} where \texttt{view} is the current figure that needs to be updated after the transformation, \texttt{points} is the matrix storing the data and \texttt{m} is the matrix transformation to be applied to each data point.
	
	Apply the function \texttt{analyzeMatrix(m)} to any matrix to inspect its determinant, eigenvalues, eigenvectors, Jordan matrix and condition number.
	
\end{flushleft}

\subsubsection*{Rotation}
\noindent
\begin{center}
	\begin{minipage}{.3\linewidth}
		\begin{center}
			\textit{Rotate around $x$ axis}
		\end{center}
		$$\left[ \begin{smallmatrix} 
		1 & 0 & 0\\
		0 & \cos\alpha & -\sin\alpha\\
		0 & \sin\alpha & \cos\alpha 
		\end{smallmatrix} \right]$$
	\end{minipage}%
	\begin{minipage}{.3\linewidth}
		\begin{center}
			\textit{Rotate around $y$ axis}
		\end{center}
		$$\left[ \begin{smallmatrix} 
		\cos\alpha & 0 & \sin\alpha\\
		0 & 1 & 0\\
		-\sin\alpha & 0 & \cos\alpha 
		\end{smallmatrix} \right]$$
	\end{minipage}
	\begin{minipage}{.3\linewidth}
		\begin{center}
			\textit{Rotate around $z$ axis}
		\end{center}
		$$\left[ \begin{smallmatrix}
		\cos\alpha & -\sin\alpha & 0\\
		\sin\alpha & \cos\alpha & 0\\
		 0 & 0 & 1
		\end{smallmatrix} \right]$$
	\end{minipage}
\end{center}

\begin{center}
	\texttt{m = matrix(3, 'rotation', axis, a)}
\end{center}
%x 0.7
%y 0.5
\begin{figure}[H]
	\centering
	\begin{subfigure}{.41\textwidth}
		\centering
		\includegraphics[width=\linewidth]{img/3dnormal}
	\end{subfigure}%
	\begin{subfigure}{.41\textwidth}
		\centering
		\includegraphics[width=\linewidth]{img/3drotation}
	\end{subfigure}
	\caption{Rotation around $x$ axis by 0.7 radians and $y$ axis by 0.5 radians.}
	\label{fig:rot}
\end{figure}
\subsubsection*{Shear}
\noindent
\begin{center}
	\begin{minipage}{.3\linewidth}
		\begin{center}
			\textit{Shear along $x$ axis}
		\end{center}
		$$\left[ \begin{smallmatrix} 
		1 & 0 & 0\\
		f_1 & 1 & 0\\
		f_2 & 0 & 1
		\end{smallmatrix} \right]$$
	\end{minipage}%
	\begin{minipage}{.3\linewidth}
		\begin{center}
			\textit{Shear along $y$ axis}
		\end{center}
		$$\left[ \begin{smallmatrix} 
		1 & f_1 & 0\\
		0 & 1 & 0\\
		0 & f_2 & 1
		\end{smallmatrix} \right]$$
	\end{minipage}
	\begin{minipage}{.3\linewidth}
		\begin{center}
			\textit{Shear along $z$ axis}
		\end{center}
		$$\left[ \begin{smallmatrix}
		1 & 0 & f_1 \\
		0 & 1 & f_2\\
		0 & 0 & 1
		\end{smallmatrix} \right]$$
	\end{minipage}
\end{center}
\begin{center}
	\texttt{m = matrix(3, 'shear', axis, f\_1, f\_2)}
\end{center}
%x 0.9 -0.7
\begin{figure}[H]
	\centering
	\begin{subfigure}{.41\textwidth}
		\centering
		\includegraphics[width=\linewidth]{img/3dnormal}
	\end{subfigure}%
	\begin{subfigure}{.41\textwidth}
		\centering
		\includegraphics[width=\linewidth]{img/3dshear}
	\end{subfigure}
	\caption{Shear along $x$ axis by factors $f_1 = 0.9$ and $f_2 = -0.7$}
	\label{fig:rot}
\end{figure}
\subsubsection*{Mirror}
\noindent
\begin{center}
	\begin{minipage}{.3\linewidth}
		\begin{center}
			\textit{Reflect $x$ component}
		\end{center}
		$$\left[ \begin{smallmatrix} 
		-1 & 0 & 0\\
		0 & 1 & 0\\
		0 & 0 & 1
		\end{smallmatrix} \right]$$
	\end{minipage}%
	\begin{minipage}{.3\linewidth}
		\begin{center}
			\textit{Reflect $y$ component}
		\end{center}
		$$\left[ \begin{smallmatrix} 
		1 & 0 & 0\\
		0 & -1 & 0\\
		0 & 0 & 1
		\end{smallmatrix} \right]$$
	\end{minipage}
	\begin{minipage}{.3\linewidth}
		\begin{center}
			\textit{Reflect $z$ component}
		\end{center}
		$$\left[ \begin{smallmatrix}
		1 & 0 & 0\\
		0 & 1 & 0\\
		0 & 0 & -1
		\end{smallmatrix} \right]$$
	\end{minipage}
\end{center}
\begin{center}
	\texttt{m = matrix(3, 'reflection', axis)}
\end{center}
%from shear reflect across z
\begin{figure}[H]
	\centering
	\begin{subfigure}{.41\textwidth}
		\centering
		\includegraphics[width=\linewidth]{img/3dshear}
	\end{subfigure}%
	\begin{subfigure}{.41\textwidth}
		\centering
		\includegraphics[width=\linewidth]{img/3dreflection}
	\end{subfigure}
	\caption{Reflect sheared body across $z$ axis}
	\label{fig:rot}
\end{figure}
\subsubsection*{Scaling}
Any diagonal matrix applies an (anisotropic) scaling transformation.
$$\left[ \begin{smallmatrix} 
s_x & 0 & 0\\
0 & s_y & 0\\
0 & 0 & s_z 
\end{smallmatrix} \right]$$
\begin{center}
	\texttt{m = matrix(3, 'scale', s\_x, s\_y, s\_z)}
\end{center}
% 3 2 1
\begin{figure}[H]
	\centering
	\begin{subfigure}{.41\textwidth}
		\centering
		\includegraphics[width=\linewidth]{img/3dnormal}
	\end{subfigure}%
	\begin{subfigure}{.41\textwidth}
		\centering
		\includegraphics[width=\linewidth]{img/3dscale}
	\end{subfigure}
	\caption{Anisotropic scaling by factors $s_x = 3$, $s_y = 2$ and $s_z = 1$}
	\label{fig:rot}
\end{figure}
\subsubsection*{Translation}
requires $4 \times 4$ homogeneous coordinates.
$$\left[ \begin{smallmatrix} 
1 & 0 & 0 & d_x\\
0 & 1 & 0 & d_y\\
0 & 0 & 1 & d_z\\
0 & 0 & 0 & 1 
\end{smallmatrix} \right]$$

\begin{center}
	\texttt{m = matrix(4, 'translation', d\_x, d\_y, d\_z)}
\end{center}
%1 2 -1
\begin{figure}[H]
	\centering
	\begin{subfigure}{.41\textwidth}
		\centering
		\includegraphics[width=\linewidth]{img/3dnormal}
	\end{subfigure}%
	\begin{subfigure}{.41\textwidth}
		\centering
		\includegraphics[width=\linewidth]{img/3dtranslation}
	\end{subfigure}
	\caption{Translation by offsets $d_x = 1$, $d_y = 2$ and $d_z = -1$}
	\label{fig:rot}
\end{figure}
\subsubsection*{Perspective Projection}
requires $4 \times 4$ homogeneous coordinates.
$$\left[ \begin{smallmatrix} 
1 & 0 & 0 & 0\\
0 & 1 & 0 & 0\\
0 & 0 & 1 & 0\\
0 & 0 & \frac{1}{d} & 1 
\end{smallmatrix} \right]$$
%4
\begin{center}
	\texttt{m = matrix(4, 'projection', d)}
\end{center}
\begin{figure}[H]
	\centering
	\begin{subfigure}{.41\textwidth}
		\centering
		\includegraphics[width=\linewidth]{img/3dnormal}
	\end{subfigure}%
	\begin{subfigure}{.41\textwidth}
		\centering
		\includegraphics[width=\linewidth]{img/3dprojection}
	\end{subfigure}
	\caption{Projection by factor $d = 4$}
	\label{fig:rot}
\end{figure}

\subsubsection*{Permutation Matrix}
A permutation matrix contains exactly one $1$ per row and column. When applied, a permutation matrix interchanges the axes of a vector.
Example: $$\left[ \begin{smallmatrix} 
0 & 1 & 0\\
0 & 0 & 1\\
1 & 0 & 0
\end{smallmatrix} \right]$$
\begin{figure}[H]
	\centering
	\begin{subfigure}{.41\textwidth}
		\centering
		\includegraphics[width=\linewidth]{img/3dnormal}
	\end{subfigure}%
	\begin{subfigure}{.41\textwidth}
		\centering
		\includegraphics[width=\linewidth]{img/3dpermutation}
	\end{subfigure}
	\caption{Permutation using above matrix}
	\label{fig:rot}
\end{figure}

\subsubsection*{Stochastic Transition Matrix}
In a stochastic transition matrix, the rows sum up to $1$. Example:
$$\left[ \begin{smallmatrix} 
0 & \frac{1}{2} & \frac{1}{2}\\
\frac{1}{3} & \frac{1}{3} & \frac{1}{3}\\
1 & 0 & 0
\end{smallmatrix} \right]$$

\subsubsection*{Upper Triangular Matrix}
An upper triangular matrix has only zero entries below the main diagonal, and arbitrary entries above. Example:
$$\left[ \begin{smallmatrix} 
2 & 3 & 2\\
0 & 1 & -2\\
0 & 0 & 4
\end{smallmatrix} \right]$$

\subsubsection*{Householder Matrix}
A householder matrix describes the transformation of a vector when reflected through the origin with respect to a (hyper-)plane represented by its normal vector $v$.
It can be constructed for a given (unit) vector $v$ as follows:
$$P = I - 2 \cdot v \cdot v^T$$. 
$P$ is always symmetric since $$P^T = (I- 2 \cdot v \cdot v^T)^T = I- 2 \cdot v \cdot v^T = P$$ and is its own inverse since $$PP = (I- 2 \cdot v \cdot v^T)(I- 2 \cdot v \cdot v^T) = I - 4 \cdot v \cdot v^T + 4 \cdot v \cdot v^T  v \cdot v^T = I - 4 \cdot v \cdot v^T + 4 \cdot v \cdot v^T = I$$
Thus, Householder matrices are orthogonal ($P^{-1} = P^T$).

\section{Observations}
Most of the listed transformations do not typically yield singular matrices, i.e. they can be reversed by applying the inverse of the matrix to the set of points. A few of the matrices can be made singular when setting all parameters to zero (e.g. a scaling matrix that consists of all zeros).
The stochastic transition matrix chosen as an example above is in fact singular, because two columns were chosen such that are not linearly independent. This leads to a collapse in dimensionality in the visualized result (it becomes planar in 3D space) and can no longer be inverted.

\begin{figure}[H]
	\centering
	\begin{subfigure}{.41\textwidth}
		\centering
		\includegraphics[width=\linewidth]{img/presing}
	\end{subfigure}%
	\begin{subfigure}{.41\textwidth}
		\centering
		\includegraphics[width=\linewidth]{img/sing}
	\end{subfigure}
	\caption{Applying a singular stochastic transition matrix to 3D data points.}
	\label{fig:rot}
\end{figure}

The eigenvalues of the singular transformation matrix used in above illustration are 1, $-\frac{2}{3}$ and 0. (Therefore, the determinant is also zero.) The corresponding eigenvectors are $(-0.5774, -0.5774, -0.5774)$  $(-0.5523, -0.0921, 0.8285)$ and $(0.0000, -0.7071, 0.7071)$.

%- try some other class of matrices: symmetric matrices, Laplacian Matrix, magic matrix,
%Householder matrix (what is it)
%
%
%analyze the following:
%- when do the matrices become singular?
%- What can you observe about the Eigenvalues and Eigenvectors of these matrices?

\end{document}